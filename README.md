The app is designed to help people with colorblindness see details in every picture. I as a colorblind person myself understand how important it can be to see needed details on graphs/pictures/images. The code allows us to pass a live video from any source connected to the machine through an extensive mathematical filtering process, and see the output in the real time. Because of the deep mathematical nature of the code, the FPS (Frames per second) is not great (about 15 fps on my machine) but can be improved significantly on more powerful devices.

The GUI in the app is made using Gooey:

![Dalton, made by Volynets 1_23_2025 1_46_11 PM](https://github.com/user-attachments/assets/c96b7dd1-810d-41b8-8722-762669fdabd4)

Here, two lists can be seen. The first one allows the user to choose a type of deficiency to correct, and the second one is the list of all available-to-use video ports.

Here is an example of color tests before and after Tritanopia correction:

![image](https://github.com/user-attachments/assets/4c33d394-2bcb-41ad-88a7-2143dc69740d) ![Tritanope 1_23_2025 1_48_18 PM](https://github.com/user-attachments/assets/9ff5f718-27e2-43e4-9471-2ef5e66c051e)

Inspiration was taken from: https://github.com/joergdietrich/daltonize
